{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bbe30e",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"height: 2px; background: linear-gradient(to right, #E31B1D 50%, #00A4DD 50%);\">\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    \n",
    "<div style=\"width: 20%; text-align: left;\">\n",
    "    <img src=\"logos/hpc_logo.png\" alt=\"Image Description\" width=\"100px\">\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 60%; text-align: center;\">\n",
    "    <strong><center><font size = \"6\">Python profiling</font></center></strong>\n",
    "    <br>\n",
    "    <strong><center><font size = \"4\">Python + HPC</font></center></strong>\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 20%; text-align: right;display: flex; justify-content: center;align-items: center;\">\n",
    "    <img src=\"logos/unilu_logo.png\" alt=\"Image Description\" width=\"100px\">\n",
    "</div>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<hr style=\"height: 2px; background: linear-gradient(to right, #E31B1D 50%, #00A4DD 50%);\">\n",
    "\n",
    "By: **Oscar J. CASTRO-LOPEZ** (oscar.castro@uni.lu)\n",
    "\n",
    "**University of Luxembourg | HPC | PCOG**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0. [Workshop Overview](#workshopoverview)\n",
    "1. [Introduction](#introduction)\n",
    "2. [Use Case](#usecase)\n",
    "2. [Timing Executions](#timingexecutions)\n",
    "3. [Profiling with prun](#profilingprun)\n",
    "4. [Line profiling with lprun](#profilinglprun)\n",
    "5. [Memory profiling](#memoryprofiling)\n",
    "6. [Conclusion](#conclusion)\n",
    "\n",
    "\n",
    "## 0. Workshop Overview <a name=\"workshopoverview\"></a>\n",
    "\n",
    "Welcome to the **Python + HPC** workshop. In this hands-on session, we will dive into profiling Python code to identify performance bottlenecks and optimize your applications. By the end of this workshop, you will be equipped with essential profiling tools and techniques.\n",
    "\n",
    "\n",
    "### Prerequisites \n",
    "\n",
    "Before we begin, please make sure you have the following:\n",
    "\n",
    "- A basic understanding of Python programming.\n",
    "- Have Jupyter Notebook installed and configured on your system (_better if already installed in HPC Node_).\n",
    "- Familiarity with Jupyter Notebook. \n",
    "\n",
    "### Agenda\n",
    "\n",
    "1. **Introduction to Profiling**\n",
    "2. **Timing executions**\n",
    "3. **Code profiling %prun**\n",
    "4. **Break**\n",
    "5. **Line Profiling %lprun**\n",
    "6. **Memory Profiling %mprun**\n",
    "7. **Q&A and Closing Remarks**\n",
    "\n",
    "### Workshop Key Goals\n",
    "The primary objectives of this workshop are:\n",
    "\n",
    "- To provide a basic understanding of Python code profiling and timing.\n",
    "- To equip you with practical skills in profiling Python code.\n",
    "- To explore a use case and discover bottlenecks.\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "To get started with this workshop, follow these steps:\n",
    "\n",
    "1. Clone or download the workshop materials from the [GitHub repository](https://github.com/ULHPC/python-school).\n",
    "2. Open a terminal and navigate to the workshop directory.\n",
    "3. Open this notebook (`1_Python_profiling.ipynb`) in your browser.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "<hr style=\"height: 2px; background: linear-gradient(to right, #E31B1D 50%, #00A4DD 50%);\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc78e24f",
   "metadata": {},
   "source": [
    "# 1.Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "<center><strong><font size=5 style=\"color: red;\">Why Profiling?</size></strong></center>\n",
    "\n",
    "- **Identify Bottlenecks**: Profiling helps you identify which parts of your code are consuming the most time or other resources. This allows you to focus your optimization efforts where they will have the greatest impact.\n",
    "\n",
    "- **Data-Driven Optimization**: Profiling provides concrete data about your code's performance. This data helps you make informed decisions about where to optimize based on actual measurements rather than guessing or intuition.\n",
    "\n",
    "- **Prevent Premature Optimization**: Profiling helps you avoid the common pitfall of premature optimization, which can lead to code complexity and reduced maintainability. By profiling first, you can ensure that you're optimizing areas of the code that genuinely need it.\n",
    "\n",
    "- **Prioritize Efforts**: When dealing with limited resources (time, budget, etc.), profiling helps you prioritize which parts of your code to optimize. You can focus on the critical sections that have the most significant impact on overall performance.\n",
    "\n",
    "- **Avoid Over-Engineering**: Profiling helps you strike a balance between performance and readability/maintainability. Without profiling, you might over-engineer your code for performance, making it more complex than necessary.\n",
    "\n",
    "- **Benchmark Improvements**: After making changes to your code, profiling allows you to measure the actual impact of those changes. This helps you verify that your optimizations are effective and didn't introduce new issues.\n",
    "\n",
    "- **Continuous Improvement**: Profiling should be an ongoing process. As your codebase evolves, new bottlenecks may emerge, or the performance characteristics may change. Regular profiling ensures that your code continues to perform well over time.\n",
    "\n",
    "- **Debugging**: Profilers often provide insights into unexpected behavior or errors in your code. You may discover unintended inefficiencies or even bugs that are only apparent when looking at performance data.\n",
    "\n",
    "In summary, profiling is a crucial step in the optimization process. It provides a solid foundation for making informed decisions about how to improve your code's performance efficiently and effectively.\n",
    "\n",
    "## 2. Use case KNN Classifier <a name=\"usecase\"></a>\n",
    "\n",
    "This implementation defines a KNNClassifier class with methods for fitting the model, calculating Euclidean distances, and making predictions. It uses a simple k-nearest neighbors approach to classify data points based on their proximity to training data.\n",
    "\n",
    "**Note: Code given by CHATGPT**\n",
    "\n",
    "For the purpose of testing the profiler it is not necessary to fully understand the logic behind the code. However, if more detail is required you can check: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "### Install pre-requisites: Numpy, line_profiler, memory_profiler, matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3eb01-873b-468a-9cd2-544712331dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy line_profiler memory_profiler matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e61432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        diff = (x1 - x2)\n",
    "        sqr_diff = diff ** 2\n",
    "        sqr_diff_sum = np.sum(sqr_diff)\n",
    "        return np.sqrt(sqr_diff_sum)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Calculate distances from the input point to all training points\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Sort by distance and return indices of the first k neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # Return the most common class label among the k nearest neighbors\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c6de0",
   "metadata": {},
   "source": [
    "The following code cell shows a basic example of using the KNNClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624eaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train data\n",
    "X_train = np.array([[1, 2], [2, 3], [3, 4], [5, 6]])\n",
    "y_train = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Create an object and pass data\n",
    "knn = KNNClassifier(k=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create test data\n",
    "X_test = np.array([[2, 3], [4, 5]])\n",
    "\n",
    "# Generate Predictions\n",
    "predictions = knn.predict(X_test)\n",
    "# Print result\n",
    "print(predictions)  # Output: [0 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0ded5",
   "metadata": {},
   "source": [
    "Create a bigger dataset with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with random data\n",
    "rows = 100\n",
    "cols = 50\n",
    "np.random.seed(699)\n",
    "X_train = np.random.rand(rows*cols).reshape((rows,cols))\n",
    "y_train = np.random.randint(2, size=rows)\n",
    "print(f'X_train shape {X_train.shape} - y_train shape {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9285e3a",
   "metadata": {},
   "source": [
    "Use the KNNClassifier and check how many are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNClassifier(k=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create random indices to test\n",
    "test_size = 10\n",
    "X_test = np.random.randint(rows, size=test_size)\n",
    "\n",
    "# Generate Predictions\n",
    "predictions = knn.predict(X_train[X_test])\n",
    "print(f'Prediction {predictions}')\n",
    "print(f'Label      {y_train[X_test]}')\n",
    "# Calculate the number of equal elements\n",
    "print(f'correct {np.sum(y_train[X_test] == predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050d317",
   "metadata": {},
   "source": [
    "Create an even bigger dataset with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eff79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with bigger-random data\n",
    "rows = 1000\n",
    "cols = 50\n",
    "np.random.seed(699)\n",
    "X_train = np.random.rand(rows*cols).reshape((rows,cols))\n",
    "y_train = np.random.randint(2, size=rows)\n",
    "print(f'X_train shape {X_train.shape} - y_train shape {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d44ff1",
   "metadata": {},
   "source": [
    "Create the KNNClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ef6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNClassifier(k=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create random indices to test\n",
    "test_size = 100\n",
    "X_test = np.random.randint(rows, size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a94ec",
   "metadata": {},
   "source": [
    "## 3. Timing executions <a name=\"timingexecutions\"></a>\n",
    "\n",
    "Take the elapsed time of generating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ddbb0",
   "metadata": {},
   "source": [
    "### Taking time inside the code\n",
    "\n",
    "There are several ways to measure the execution time in Python. For example:\n",
    "\n",
    "- `time.time()` function: measure the total time elapsed to execute the script in seconds.\n",
    "    - This value is often referred to as \"wall-clock time\" or \"real time.\"\n",
    "    - It includes the time spent in sleeping or waiting for I/O operations, making it suitable for measuring the total elapsed time for a program or a specific task.\n",
    "- `time.process_time()`: returns the current CPU time used by the current process in seconds, as a floating-point number. \n",
    "    - This value represents the amount of CPU time consumed by your program and excludes time spent in sleep or waiting for I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "time.sleep(2.4)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f929048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_cpu_time = time.process_time()\n",
    "time.sleep(2.4)\n",
    "end_cpu_time = time.process_time()\n",
    "elapsed_cpu_time = end_cpu_time - start_cpu_time\n",
    "print(f\"CPU time used: {elapsed_cpu_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0ba3f",
   "metadata": {},
   "source": [
    "- **timeit module**: module in Python is a built-in library that provides a simple way to measure the execution time of small code snippets.\n",
    "    - It has both a Command-Line Interface as well as a callable one.\n",
    "    - Measures \"wall-clock\" time.\n",
    "    - For more details: https://docs.python.org/3/library/timeit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "code_to_measure = \"\"\"\n",
    "result = sum(range(1000))\n",
    "\"\"\"\n",
    "\n",
    "time_taken = timeit.timeit(code_to_measure, number=10000)\n",
    "\n",
    "print(f\"Time taken: {time_taken} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aac435",
   "metadata": {},
   "source": [
    "- **DateTime module**: measure the execution time in the hours-minutes-seconds format.\n",
    "    - Measures wall time, total elapsed time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4390b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "time.sleep(63)\n",
    "end_time = datetime.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2d673",
   "metadata": {},
   "source": [
    "### Take the elapsed time of running a cell\n",
    "\n",
    "`%time` is used to measure the execution time of a single statement or expression in a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c41688",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d72a85",
   "metadata": {},
   "source": [
    "`%timeit`  is used to perform more comprehensive timing analysis. It runs the specified code cell multiple times and calculates statistics like the average, best, and worst execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32d6e0",
   "metadata": {},
   "source": [
    "For a cell with multiple statements use `%%` before the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "knn = KNNClassifier(k=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create random indices to test\n",
    "test_size = 100\n",
    "X_test = np.random.randint(rows, size=test_size)\n",
    "predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c6cc8e",
   "metadata": {},
   "source": [
    "With only one repetion and one number:\n",
    "- `-n` how many times to execute ‘statement’\n",
    "- `-r` how many times to repeat the timer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "knn = KNNClassifier(k=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create random indices to test\n",
    "test_size = 100\n",
    "X_test = np.random.randint(rows, size=test_size)\n",
    "predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302856b",
   "metadata": {},
   "source": [
    "- Second (s)\n",
    "- \n",
    "Millisecond (ms- 1 second = 1,000 millisecond\n",
    "- Microsecond (&micro;s) - 1 second = 1,000,000 microsecond\n",
    "\n",
    "Save the result of **timeit** with the command `%timeit -o my_code(args)`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_elapsed_time = %timeit -o knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best', predict_elapsed_time.best)\n",
    "print('Average', predict_elapsed_time.average)\n",
    "print('Standard Deviation', predict_elapsed_time.stdev)\n",
    "print('Worst', predict_elapsed_time.worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888f507",
   "metadata": {},
   "source": [
    "## 4. Profiling with prun <a name=\"profilingprun\"></a>\n",
    "\n",
    "Python contains a built-in code profiler (which you can read about in the Python documentation), but IPython offers a much more convenient way to use this profiler, in the form of the magic function %prun.\n",
    "\n",
    "\n",
    "```bash\n",
    "%prun my_function()\n",
    "```\n",
    "cProfile will run the function and collect data on how much time is spent in each function or method called within my_function.\n",
    "\n",
    "Magic commands are special commands that can help you with running and analyzing data in your notebook. They add a special functionality that is not straight forward to achieve with python code or Jupyter notebook interface.\n",
    "\n",
    "Magic commands are easy to spot within the code. They are either proceeded by % if they are on one line of code or by %% if they are written on several lines.\n",
    "\n",
    "For more detail on magic commands: \n",
    "\n",
    "https://ipython.readthedocs.io/en/stable/interactive/magics.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ded9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e794751",
   "metadata": {},
   "source": [
    "The output consist on the following columns:\n",
    "- ncalls: number of times a function or method is called.\n",
    "- tottime: total time spent in the function excluding time spent in subfunctions it calls (in seconds).\n",
    "- percall: average time per call to the tottime of the function (tottime / ncalls).\n",
    "- cumtime: cumulative time that indicates the total time spent in function including subfunctions.\n",
    "- percall: average time percall to the cumtime of the function (cumtime / ncalls).\n",
    "- filename:lineno(function): provides information about the function or method, indicates the file, line number, and name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e0662",
   "metadata": {},
   "source": [
    "## 5. Line profiling with lprun <a name=\"profilinglprun\"></a>\n",
    "\n",
    "For a more detailed and granular analysis of code performance, as well as a clear and comprehensible report, you can employ the `lprun` profiler. Unlike some other profilers that provide high-level insights, `lprun` delves into the code at the line-by-line level, offering a meticulous examination of your code's execution. \n",
    "\n",
    "This can be particularly valuable when you need to pinpoint specific bottlenecks or areas for optimization within your codebase. By generating a line-by-line report, `lprun` allows you to identify exactly where the most time-consuming operations occur, aiding in the optimization process and enabling you to achieve optimal code performance.\n",
    "\n",
    "The first step is to import the `line_profiler`. Then we need to call the profiler in the following way:\n",
    "\n",
    "`%lprun -f function_to_profile code_to_run(arg)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8800eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c611fdda",
   "metadata": {},
   "source": [
    "In the following line we profile `knn.predict` function while we call the code `predictions = knn.predict(X_train[X_test])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f knn.predict predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792f5f6",
   "metadata": {},
   "source": [
    "The output of `%lprun` is the following:\n",
    "\n",
    "- **Line #**: line number of the code being profiled.\n",
    "- **Hits**: indicates how many times each line was executed.\n",
    "- **Time**: shows the total time spent on the execution of the line.\n",
    "- **Per Hit**: shows the average time, in milliseconds spent on each execution of the line.\n",
    "- **% time**: shows the percentage of total execution time spent on each line.\n",
    "- **Line Contents**: contains the actual code corresponding to the line being profiled.\n",
    "\n",
    "If we want to inspect functions called inside `knn.predict(X_train[X_test])` then we can specify another function. \n",
    "\n",
    "For example in the following command we profile `knn._predict` while we call `knn.predict(X_train[X_test])`. With this approach we can profile all functions called inside our code to track bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f knn._predict predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f knn.euclidean_distance predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa0d37",
   "metadata": {},
   "source": [
    "## 6. Memory profiling with `memit` and `mprun` <a name=\"memoryprofiling\"></a>\n",
    "\n",
    "This package allows to profile memory usage in Python code on a line-by-line basis. It's particularly useful for identifying memory leaks or memory-hungry parts of the code.\n",
    "\n",
    "First, load the package extension using the `%load_ext memory_profiler` magic command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8324c",
   "metadata": {},
   "source": [
    "The `memit` command measures the memory usage of a single statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit predictions = knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e18de",
   "metadata": {},
   "source": [
    "The output of `memit` is limited to see the peak memory and increment. For a more detailed report line by line we must use `mprof`. However, we require that our code is stored in a file. In the following cell we use the magic command `%%file filename.py` at the beginning of the cell. That command saves in `filename.py` what is inside the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da783385",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file knn_demo.py\n",
    "\n",
    "import numpy as np\n",
    "from memory_profiler import profile\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        diff = (x1 - x2)\n",
    "        sqr_diff = diff ** 2\n",
    "        sqr_diff_sum = np.sum(sqr_diff)\n",
    "        return np.sqrt(sqr_diff_sum)\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        # Calculate distances from the input point to all training points\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Sort by distance and return indices of the first k neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # Return the most common class label among the k nearest neighbors\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc2a7b",
   "metadata": {},
   "source": [
    "After the file is saved, we need to import the library. Additionally, we instantiate the KNNClassifier and create a test vector before profiling the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdc0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn_demo import KNNClassifier\n",
    "knn = KNNClassifier(k=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create random indices to test\n",
    "test_size = 100\n",
    "X_test = np.random.randint(rows, size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be61e88",
   "metadata": {},
   "source": [
    "Similar to the `lprun` syntax, to use `mprun` in a Jupyter notebook we need to use the command:\n",
    "\n",
    "`%mprun -f function_to_profile code_to_run(arg)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -f knn._predict knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dab22c",
   "metadata": {},
   "source": [
    "In the `mprof` output, each row provides detailed information about memory usage and code execution. The columns in the output serve the following purposes:\n",
    "\n",
    "1. Line Number: This is the first column and indicates the line number in the code where memory measurements were taken.\n",
    "\n",
    "2. Mem Usage (MiB): The second column, represented in Mebibytes (MiB), displays the amount of memory used at each line of code. It shows how much memory is consumed or released during code execution.\n",
    "\n",
    "3. Increment (MiB): In the third column, the increment indicates the change in memory usage compared to the previous line. Positive values represent memory allocation, while negative values indicate memory deallocation.\n",
    "\n",
    "4. Occurrences: This fourth column reveals how many times a particular line of code was executed. It provides insights into code behavior and repetition.\n",
    "\n",
    "5. Code Content: The fifth column contains the actual code present on the line.\n",
    "\n",
    "Measurements are shown in MiB (Mebibytes) but you can convert it to MB (Megabytes) using the conversion factor (1 MiB ≈ 1.048576 MB).\n",
    "\n",
    "We can also profile multiple functions at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -f knn.fit -f knn.predict -f knn._predict -f knn.euclidean_distance knn.predict(X_train[X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b9cdb",
   "metadata": {},
   "source": [
    "<strong><font size=2 style=\"color: red;\">Why the output shows MiB equal to 0?</size></strong>\n",
    "- Probably because the size of the variable is too small.\n",
    "\n",
    "Run the following profiling command only for the `euclidean_distance` function and increment the size of the input arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -f knn.euclidean_distance knn.euclidean_distance(np.arange(cols*10000000), np.arange(cols*10000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3deeee0",
   "metadata": {},
   "source": [
    "### A \"simple\" code snippet to profile with `mprun` and different ways to use it\n",
    "\n",
    "There are different ways to use `mprun`, we already shown one using Jupyter notebooks. We can also use `mprun` with the line command.\n",
    "\n",
    "Let's start by creating another file that contains a function named `sum_of_lists()` and it is called at the end of the file.\n",
    "\n",
    "The main difference is that we require to import the following:\n",
    "```python \n",
    "from memory_profiler import profile\n",
    "```\n",
    "And add the decorator `@profile` on the functions that we want to profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file delete_me.py\n",
    "\n",
    "from memory_profiler import profile\n",
    "import numpy as np\n",
    "\n",
    "@profile\n",
    "def sum_of_lists(N):\n",
    "    a = [0] * (N*10)\n",
    "    b = [1] * (N*20)\n",
    "    c = [1.0] * (N*30)\n",
    "    d = ['A'] * (N*40)\n",
    "    e = np.arange(N*10)\n",
    "    f = [j ^ 3 for j in range(N)]\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        L = [j ^ 3 for j in range(N)]\n",
    "        total += sum(L)\n",
    "        del L # remove reference to L\n",
    "    del a\n",
    "    del b\n",
    "    del c\n",
    "    del d\n",
    "    del e\n",
    "    del f\n",
    "    return total\n",
    "\n",
    "sum_of_lists(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5201d",
   "metadata": {},
   "source": [
    "We can profile with `python -m memory_profiler file_to_profile.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m memory_profiler delete_me.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d79034",
   "metadata": {},
   "source": [
    "Or we can profile with `!mprof run file_to_profile.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof run delete_me.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619a7d3",
   "metadata": {},
   "source": [
    "We can also plot the recorded memory usage (by default, the last one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof plot -o mem_usage_plot.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c522c1",
   "metadata": {},
   "source": [
    "Output of `mprof plot`:\n",
    "\n",
    "![image](mem_usage_plot.png \"mprof output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d9863",
   "metadata": {},
   "source": [
    "<strong><font size=4 style=\"color: red;\">Why the output of `mprof` does not show same numbers wen allocating/deallocating memory?</size></strong>\n",
    "\n",
    "Memory allocation and deallocation in Python are not as straightforward as they may seem due to:\n",
    "- Garbage collection\n",
    "- Memory fragmentation\n",
    "- Optimizations by Python\n",
    "- Operating system and Hardware\n",
    "\n",
    "Because of these factors, you may see varying memory usage changes when creating and deleting variables in Python. \n",
    "\n",
    "Python's memory management is dynamic and complex, and the exact behavior can vary depending on many factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075204f3",
   "metadata": {},
   "source": [
    "## 7. Conclusions / Take away <a name=\"conclusion\"></a>\n",
    "\n",
    "Profiling is a valuable skill for any Python developer, and it can lead to more efficient, faster, and higher-quality code. It's a tool for diagnosing and solving performance issues and should be part of the toolkit of every Python programmer.\n",
    "\n",
    "In this tutorial, we've covered the following key areas:\n",
    "- Understanding profiling tools.\n",
    "- Identifying bottlenecks.\n",
    "- Debugging skills.\n",
    "\n",
    "**Note**: The reviewed tools work best for sequential applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c0314",
   "metadata": {},
   "source": [
    "--------\n",
    "In case of need to reload libraries: Use the following command just once to automatically reload libraries. Otherwise, we would require to restart the notebook each time we want to reload a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
